{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta, date, time\n",
    "import numpy as np\n",
    "from my_keys import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get timestamp in correct format for tomorrow 0,12 and 24 \n",
    "def get_tomorrow():\n",
    "    #make tomorow day, by adding one day to today\n",
    "    date_tomorrow = date.today() + timedelta(days=1)\n",
    "    #make three times: 00:00:00,12:00:00,23:59:59\n",
    "    time_start = time(hour=0, minute=0, second=0)\n",
    "    time_middle = time(hour=12, minute=0, second=0)\n",
    "    time_end = time(hour=23, minute=59, second=59)\n",
    "    #combine tomorow day and the times\n",
    "    datetime_start = datetime.combine(date_tomorrow, time_start).strftime('%Y-%m-%dT%H:%M')\n",
    "    datetime_middle = datetime.combine(date_tomorrow, time_middle).strftime('%Y-%m-%dT%H:%M')\n",
    "    datetime_end = datetime.combine(date_tomorrow, time_end).strftime('%Y-%m-%dT%H:%M')\n",
    "    #return three tomorow times\n",
    "    return datetime_start,datetime_middle,datetime_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_forcast function that het a list of citie names and return the weather_forcast for tomorow\n",
    "def weather_forcast(cities_df,openweather_api_key):\n",
    "   \n",
    "    \n",
    "    cities_list  = []#i want to use the cities information from this api, but it is not a good source i think\n",
    "    weather_list = []#a list to stor all citys weathers\n",
    "    error =[]# i try to catch errors and manage them, its just to control them, ill make it right later\n",
    "    dt_start,dt_middle,dt_end = get_tomorrow() #generate the datetime format variabels fro tommorrow times\n",
    "    #a loop for all citiess in city dataframe\n",
    "    for index, city in cities_df.iterrows():\n",
    "        \n",
    "        #sent a requiest to openweather with city name and mykey\n",
    "        city_r = requests.get(f\"http://api.openweathermap.org/data/2.5/forecast?q={city['city']}&appid={openweather_api_key}&units=metric\")\n",
    "        \n",
    "        #check if the responce is not ok\n",
    "        if city_r.status_code != 200:\n",
    "            error.append(city+\" got errpr code: \"+ str(city_r.status_code)) #add the  error code with the message include the name of city\n",
    "            continue #when this city has error just continue the for loop\n",
    "        \n",
    "        city_j = city_r.json() #convert the reponse to json\n",
    "        \n",
    "        cities_list.append(city_j['city']) #add citys information to cities_list\n",
    "        \n",
    "        # the api gives us a list of weather detail for every 3 hours for next 5 days and store each details in a dict \n",
    "        for detail in city_j['list']:\n",
    "            weather_details_dict = {} #create an empty weather dict\n",
    "            \n",
    "            #choose that details that we want in the key names\n",
    "            weather_details_dict[\"temperature\"] = detail['main']['temp']\n",
    "            weather_details_dict[\"temp_min\"] = detail['main']['temp_min']\n",
    "            weather_details_dict[\"temp_max\"] = detail['main']['temp_max']\n",
    "            weather_details_dict[\"feels_like\"] = detail['main']['feels_like']\n",
    "            weather_details_dict[\"pressure\"] = detail['main']['pressure']\n",
    "            weather_details_dict[\"humidity\"] = detail['main']['humidity']\n",
    "            weather_details_dict[\"weather\"] = detail['weather'][0]['main']\n",
    "            weather_details_dict[\"weather_description\"] = detail['weather'][0]['description']\n",
    "            weather_details_dict[\"clouds\"] = detail['clouds']['all']\n",
    "            weather_details_dict[\"wind_speed\"] = detail['wind']['speed']\n",
    "            weather_details_dict[\"date_time_3h\"] = detail['dt_txt']\n",
    "            \n",
    "            weather_details_dict[\"city_id\"] = city['city_id'] # use the city_id from cities_df to use as forigen key\n",
    "            weather_list.append(weather_details_dict) # add dict to weather_list\n",
    "    \n",
    "    \n",
    "    df_weather = pd.DataFrame(weather_list) #convert the weather_list to pandas dataframe\n",
    "    df_weather['date_time_3h'] = pd.to_datetime(df_weather['date_time_3h']) #convert the date_time_3h to pdatetime format\n",
    "    df_weather = df_weather.loc[lambda df_ : (df_['date_time_3h'] >= dt_start) &  (df_['date_time_3h'] <= dt_end)] #i select just the tomorros datas\n",
    "    \n",
    "    \n",
    "    df_cities = pd.json_normalize(cities_list) #convert df_cities to pandas data frame\n",
    "    df_cities.rename(columns={'id':'city_id'}, inplace=True) # rename the id column to city_id\n",
    "    \n",
    "    #retuen both dafata frames and error list\n",
    "    return df_weather,df_cities,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# function that collect the data for each city in cities_list from the wikipedia and wft-geo-db.p.rapidapi.com api\n",
    "def get_cities(cities_list,RapidAPI_key):\n",
    "    #make a empty data frame with the columns that we want\n",
    "    city_columns= ['id', 'wikiDataId', 'type', 'name', 'country', 'countryCode', 'region', 'mayor', 'elevationMeters', 'latitude', 'longitude',\t'population', 'timezone']\n",
    "    cities_df = pd.DataFrame(columns= city_columns)\n",
    "    error =[]# i try to catch errors and manage them, its just to control them, ill make it right later\n",
    "    #loop on all cities in cities_list\n",
    "    for city in cities_list :\n",
    "        #collect the wiki id for cities an the name of mayoe for ich city\n",
    "        wiki_url = f\"https://en.wikipedia.org/wiki/{city}\" #make wikipedia url with the city name\n",
    "        wiki_city_r = requests.get(wiki_url) # send a request to wikipedia \n",
    "        \n",
    "        if wiki_city_r.status_code != 200:\n",
    "            error.append(city+\" got errpr code: \"+ str(wiki_city_r.status_code)+\"from wikipedia\") #add the  error code with the message include the name of city\n",
    "            continue #when this city has error just continue the for loop\n",
    "        \n",
    "        wiki_city_soup = BeautifulSoup(wiki_city_r.content, \"html.parser\") #convert the response to BeautifulSoup variable\n",
    "        #find the html a element that its string contains 'Mayor'  then find its grandparent then find the name of mayor in its place\n",
    "        try: city_mayor = wiki_city_soup.find('a' , text = re.compile(\".*Mayor.*\")).parent.parent.find('td').find('a').string \n",
    "        except: city_mayor = 'Unknown' # managing error, when ther is no mayor name\n",
    "        # two selects to find the wikiId for each city\n",
    "        #  city_wiki_id = wiki_city_soup.select('li#t-wikibase.mw-list-item a')[0]['href'].split('/')[-1]\n",
    "        city_wiki_id = wiki_city_soup.select('div#mw-navigation div#mw-panel nav#p-tb div.vector-menu-content ul.vector-menu-content-list li#t-wikibase.mw-list-item a')[0]['href'].split('/')[-1]\n",
    "        \n",
    "        #generate a url to get the city information from /wft-geo-db.p.rapidapi.com\n",
    "        url = f\"https://wft-geo-db.p.rapidapi.com/v1/geo/cities/{city_wiki_id}\"\n",
    "        headers = {\n",
    "\t                \"X-RapidAPI-Key\": RapidAPI_key, #######################\n",
    "\t                \"X-RapidAPI-Host\": \"wft-geo-db.p.rapidapi.com\"\n",
    "                    }\n",
    "        city_informatin_r = requests.request(\"GET\", url, headers=headers)\n",
    "        \n",
    "        if wiki_city_r.status_code != 200:\n",
    "            error.append(city+\" got errpr code: \"+ str(wiki_city_r.status_code)+\"from wft-geo-db.p.rapidapi.com\") #add the  error code with the message include the name of city\n",
    "            continue #when this city has error just continue the for loop\n",
    "        \n",
    "        city_informatin_j = city_informatin_r.json() #covert responce to json\n",
    "        city_informatin_df = pd.json_normalize(city_informatin_j['data']) #convert json to pandas dataframe\n",
    "        city_informatin_df[\"mayor\"] = city_mayor #add the mayor name in city_informatin_df\n",
    "        city_informatin_df = city_informatin_df[city_columns] #select the columns that we want\n",
    "        cities_df = pd.concat([cities_df,city_informatin_df]) #concat the city information with the cities_df\n",
    "    #make a rename dict to rename the columns as we want    \n",
    "    city_columns_rename= {'id' : 'city_id', 'wikiDataId' : 'wiki_data_id', 'name' : 'city', 'elevationMeters' : 'elevation', 'countryCode' : 'country_code'}\n",
    "    cities_df.rename(columns = city_columns_rename, inplace=True)#aplly rename with our rename dict\n",
    "    \n",
    "    cities_df['population'] = pd.to_numeric(cities_df['population']) # convert 'population' column to numeric\n",
    "    cities_df['city_id'] = pd.to_numeric(cities_df['city_id']) # convert 'city_id' column to numeric\n",
    "    cities_df.reset_index(drop=True, inplace= True) #rest index for cities_df\n",
    "    return cities_df,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the key as intertaudi \n",
    "#function get all aiports for ich city in cities_df\n",
    "def get_citys_airports(cities_df,RapidAPI_key):\n",
    "    #make a empty data frame with the columns that we want\n",
    "\tcolumns=['icao','iata','name','short_name','longitude_deg','iso_country','latitude_deg','city_name','city_id']\n",
    "\tairports_df = pd.DataFrame(columns=columns)\n",
    "\terror =[]# i try to catch errors and manage them, its just to control them, ill make it right later\n",
    "\t# loop for every cities in cities_df\n",
    "\tfor index,city in cities_df.iterrows():\n",
    "\t\t#generate a request for aerodatabox.p.rapidapi.com, that give us all airport for that city name\n",
    "\t\turl = \"https://aerodatabox.p.rapidapi.com/airports/search/term\"\t\n",
    "\t\tquerystring = {\"q\":city['city'],\"limit\":\"10\"}\n",
    "\t\theaders = {\n",
    "\t\t\t\"X-RapidAPI-Key\": RapidAPI_key,\n",
    "\t\t\t\"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\"\n",
    "\t\t\t}\n",
    "\t\tairports_r = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "\t\tif airports_r.status_code != 200:\n",
    "\t\t\terror.append(city['city'] + \" got errpr code: \"+ str(airports_r.status_code)) #add the  error code with the message include the name of city\n",
    "\t\t\tcontinue #when this city has error just continue the for loop\n",
    "\t\t\n",
    "\t\tairports_j = airports_r.json()#convert to json\n",
    "\t\tif len(airports_j['items'])==0: #check if the city has no airport\n",
    "\t\t\terror.append(city['city'] + \" has no airport\") #add the  error  with the message include the name of city\n",
    "\t\t\tcontinue #when this city has error just continue the for loop\n",
    "\n",
    "\t\tdf_airports =pd.json_normalize(airports_j['items'])#convert to pandas dataframe\n",
    "\t\tdf_airports = df_airports.loc[lambda df_ : df_['countryCode'] == city['country_code']] #ignore the same name cities of other country\n",
    "\t\trename_dict = {'location.lat' : 'latitude_deg', 'location.lon' : 'longitude_deg', 'municipalityName': 'city_name', 'countryCode' : 'iso_country',\n",
    "\t\t\t\t\t\t\t\t'shortName' : 'short_name'}#make a rename dict that wee want to rename\n",
    "\t\tdf_airports.rename(columns=rename_dict, inplace=True) #aplly the rename\n",
    "\t\tdf_airports['city_id'] = pd.to_numeric(city['city_id'])# convert 'city_id' column to numeric\n",
    "\t\tdf_airports = df_airports[columns]#select the columns that we want\n",
    "\t\tairports_df = pd.concat([airports_df,df_airports])#concat the airports for each city\n",
    "\tairports_df.reset_index(drop=True, inplace=True)\n",
    "\treturn airports_df,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    " #function get all arrival flights for every airport in airports_df \n",
    "def get_arrival_flights(airports,RapidAPI_key):\n",
    "    #make a empty data frame with the columns that we want\n",
    "    columns=['flight_NO', 'flight_status', 'dep_airport', 'dep_airport_icao', 'dep_airport_iata','sched_arr_loc_time',\n",
    "                                    'sched_arr_Utc', 'terminal' , 'airline','aircraf', 'icao']\n",
    "    arrival_flights_df = pd.DataFrame(columns=columns)\n",
    "    #make a rename dict that wee want to rename\n",
    "    rename_dict= {'number':'flight_NO', 'status':'flight_status', \n",
    "                        'movement.airport.name' : 'dep_airport','movement.airport.icao' : 'dep_airport_icao', 'movement.airport.iata':'dep_airport_iata', \n",
    "                        'movement.scheduledTimeLocal' : 'sched_arr_loc_time', 'movement.scheduledTimeUtc' : 'sched_arr_Utc', 'movement.terminal': 'terminal',\n",
    "                        'airline.name':'airline', 'aircraft.model' :'aircraf'}\n",
    "    error = []# i try to catch errors and manage them, its just to control them, ill make it right later\n",
    "    dt_start,dt_middle,dt_end = get_tomorrow() #generate the datetime format variabels fro tommorrow times\n",
    "    #loop for all airports in airports\n",
    "    for index,airport in airports.iterrows():\n",
    "        #generate a request for aerodatabox.p.rapidapi.com, that give us all arrival flights for that airport icao\n",
    "        url = f\"https://aerodatabox.p.rapidapi.com/flights/airports/icao/{airport['icao']}/{dt_middle}/{dt_end}\"\n",
    "        querystring = {\"withLeg\":\"false\",\"direction\":\"Arrival\",\"withCancelled\":\"false\",\"withCodeshared\":\"false\",\"withCargo\":\"false\",\"withPrivate\":\"false\",\"withLocation\":\"false\"}\n",
    "        headers = {\n",
    "            \"X-RapidAPI-Key\": RapidAPI_key,\n",
    "            \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\"\n",
    "        }\n",
    "        arrivals_r = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "        \n",
    "        if arrivals_r.status_code != 200:\n",
    "            error.append(airport['icao'] + \" got errpr code: \" + str(arrivals_r.status_code))#add the error code with the message include the icao\n",
    "            continue #when this airport has error just continue the for loop\n",
    "        \n",
    "        arrivals_j = arrivals_r.json() #convert to json\n",
    "        \n",
    "        if len(arrivals_j['arrivals'])==0: #check if the airport has no flight\n",
    "            error.append(airport['icao'] + \" has no flight\")#add the error with the message include the icao\n",
    "            continue #when this airport has error just continue the for loop\n",
    "        \n",
    "        #convert json to pandas dataframe andd sort it by movement.scheduledTimeLocal\n",
    "        arrivals_df = pd.json_normalize(arrivals_j['arrivals']).sort_values(by='movement.scheduledTimeLocal')\n",
    "\n",
    "        \n",
    "        # clean df\n",
    "        \n",
    "        #some air ports dont have terminal, i try to catch the crash\n",
    "        try: arrivals_df = arrivals_df[['number', 'status', \n",
    "                        'movement.airport.name','movement.airport.icao', 'movement.airport.iata', \n",
    "                        'movement.scheduledTimeLocal', 'movement.scheduledTimeUtc', 'movement.terminal'\n",
    "                        'airline.name', 'aircraft.model']]\n",
    "        except: arrivals_df = arrivals_df[['number', 'status', \n",
    "                        'movement.airport.name','movement.airport.icao', 'movement.airport.iata', \n",
    "                        'movement.scheduledTimeLocal', 'movement.scheduledTimeUtc',\n",
    "                        'airline.name', 'aircraft.model']]\n",
    "        \n",
    "        arrivals_df.rename(columns=rename_dict , inplace=True)#apply rename \n",
    "        arrivals_df['icao'] = airport['icao']#  add the icaro column with the airpot icaro to use as forigen key\n",
    "    \n",
    "        arrival_flights_df = pd.concat([arrival_flights_df,arrivals_df])#concat eacht airport flights to resault dafataframe\n",
    "    arrival_flights_df.reset_index(drop=True, inplace=True)\n",
    "    return arrival_flights_df,error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function get extra information for ich city in cities_df\n",
    "def get_citys_informations(cities_df, RapidAPI_key):\n",
    "    #make three empty data frame with the columns that we want for hotels, landmark and transport\n",
    "\tcolumns=['id','name','type','latitude','longitude','city_id']\n",
    "\trename_dict = {'geoId' : 'id'}#make a rename dict that wee want to rename\n",
    "\thotels = pd.DataFrame(columns=columns)\n",
    "\thotels_df = pd.DataFrame(columns=columns)\n",
    "\tlandmarks= pd.DataFrame(columns=columns)\n",
    "\tlandmark_df = pd.DataFrame(columns=columns)\n",
    "\ttransports = pd.DataFrame(columns=columns)\n",
    "\ttransport_df = pd.DataFrame(columns=columns)\n",
    "\terror =[]# i try to catch errors and manage them, its just to control them, ill make it right later\n",
    "\t# loop for every cities in cities_df\n",
    "\tfor index,city in cities_df.iterrows():\n",
    "\t\t#generate a request for \"hotels4.p.rapidapi.com\", that give us all airport for that city name\n",
    "\t\t\n",
    "\t\turl = \"https://hotels4.p.rapidapi.com/locations/v2/search\"\n",
    "\t\tquerystring = {\"query\":city['city'],\"locale\":\"en_US\",\"currency\":\"USD\"}\n",
    "\n",
    "\t\theaders = {\n",
    "\t\t\t\t\"X-RapidAPI-Key\": RapidAPI_key,\n",
    "\t\t\t\t\"X-RapidAPI-Host\": \"hotels4.p.rapidapi.com\"\n",
    "\t\t\t\t}\n",
    "\t\tcity_extra_information_r = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "\t\tif city_extra_information_r.status_code != 200:\n",
    "\t\t\terror.append(city['city'] + \" got errpr code: \"+ str(city_extra_information_r.status_code)) #add the  error code with the message include the name of city\n",
    "\t\t\tcontinue #when this city has error just continue the for loop\n",
    "\t\t\n",
    "\t\tcity_extra_information_j = city_extra_information_r.json()#convert to json\n",
    "\t\tcity_hotels = city_extra_information_j['suggestions'][1]['entities']\n",
    "\t\tcity_landmark = city_extra_information_j['suggestions'][2]['entities']\n",
    "\t\tcity_transport = city_extra_information_j['suggestions'][3]['entities']\n",
    "\t\tif len(city_hotels)==0: #check if the city has no hotel\n",
    "\t\t\terror.append(city['city'] + \" has no hotels\") #add the  error  with the message include the name of city\n",
    "\t\telse :\n",
    "\t\t\thotels = pd.json_normalize(city_hotels)\n",
    "\t\t\thotels['city_id'] = pd.to_numeric(city['city_id'])# convert 'city_id' column to numeric \n",
    "\t\t\thotels.rename(columns=rename_dict, inplace=True) #aplly the rename\n",
    "\t\t\thotels = hotels[columns]#select the columns that we want\t\n",
    "  \n",
    "\t\tif len(city_landmark)==0: #check if the city has no hotel\n",
    "\t\t\terror.append(city['city'] + \" has no landmark\") #add the  error  with the message include the name of city\n",
    "\t\telse :\n",
    "\t\t\tlandmarks = pd.json_normalize(city_landmark)\n",
    "\t\t\tlandmarks['city_id'] = pd.to_numeric(city['city_id'])# convert 'city_id' column to numeric\n",
    "\t\t\tlandmarks.rename(columns=rename_dict, inplace=True) #aplly the rename\n",
    "\t\t\tlandmarks = landmarks[columns]#select the columns that we want\t\t\n",
    "\n",
    "\t\tif len(city_transport)==0: #check if the city has no hotel\n",
    "\t\t\terror.append(city['city'] + \" has no transport\") #add the  error  with the message include the name of city\n",
    "\t\telse :\n",
    "\t\t\ttransports = pd.json_normalize(city_transport)\n",
    "\t\t\ttransports['city_id'] = pd.to_numeric(city['city_id'])# convert 'city_id' column to numeric \n",
    "\t\t\ttransports.rename(columns=rename_dict, inplace=True) #aplly the rename\n",
    "\t\t\ttransports = transports[columns]#select the columns that we want\n",
    "   \n",
    "\t\trename_dict = {'geoId' : 'id'}#make a rename dict that wee want to rename\n",
    "\t\t# df_airports.rename(columns=rename_dict, inplace=True) #aplly the rename\n",
    "\n",
    "\t\thotels_df = pd.concat([hotels_df,hotels])#concat the hotels for each city\n",
    "\t\tlandmark_df = pd.concat([landmark_df,landmarks])#concat the hotels for each city\n",
    "\t\ttransport_df = pd.concat([transport_df,transports])#concat the hotels for each city\n",
    "\thotels_df.reset_index(drop=True, inplace=True)\t\n",
    "\tlandmark_df.reset_index(drop=True, inplace=True)\n",
    "\ttransport_df.reset_index(drop=True, inplace=True)\n",
    "\treturn hotels_df,landmark_df,transport_df,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will manage the update of all tables and datas, it takes a list of cities and a connection, and then \n",
    "# try to add new cities to the cities_df and new city information in airports, hotels, transports ans landmarks and then \n",
    "# it will push the new data to sql by connection that took.\n",
    "def update_information(cities_list, con):\n",
    "    #read cities table from the data base\n",
    "    excist_cities_df = pd.read_sql(\"select * from cities\", con)\n",
    "    #find new cities that arent in database\n",
    "    new_cities_list = [city for city in cities_list if (city not in excist_cities_df['city'].tolist())]\n",
    "    #generate new information for new cities\n",
    "    cities_df, cities_error = get_cities(new_cities_list,my_RapidAPI_key)\n",
    "    hotels_df,landmark_df,transport_df,error = get_citys_informations(cities_df, my_RapidAPI_key)\n",
    "    \n",
    "    #and push the data in to cieties information tables\n",
    "    cities_df['elevation'] =cities_df['elevation'].fillna(value=0)#fill na s with 0\n",
    "    cities_df.to_sql('cities', con=con, if_exists='append', index=False)\n",
    "    hotels_df.to_sql('hotels', con=con, if_exists='append', index=False)\n",
    "    landmark_df.to_sql('landmarks', con=con, if_exists='append', index=False)\n",
    "    transport_df.to_sql('transports', con=con, if_exists='append', index=False)\n",
    "    \n",
    "    #generate new information for new airports and push them to arrivals table\n",
    "    airports_df, airports_error = get_citys_airports(cities_df,my_RapidAPI_key)\n",
    "    airports_df.to_sql('airports', con=con, if_exists='append', index=False)\n",
    "    \n",
    "    #read all cities and airports from sql tables\n",
    "    excist_cities_df = pd.read_sql(\"select * from cities\", con)\n",
    "    excist_airports_df = pd.read_sql(\"select * from airports\", con)\n",
    "    \n",
    "    #generate new weather information for all cities and push them in sql database\n",
    "    weather_data, cities_df_2 ,weather_error= weather_forcast(excist_cities_df,my_openweather_api_key)\n",
    "    weather_data.to_sql('weather', con=con, if_exists='append', index=False)\n",
    "    \n",
    "    #generate new arrival flights information for all arports and push them in sql database\n",
    "    arrival_flights_df,flights_error = get_arrival_flights(excist_airports_df,my_RapidAPI_key)\n",
    "    arrival_flights_df.fillna(value =\"Unknown\").to_sql('arrivals', con=con, if_exists='append', index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['Berlin','Paris','Amsterdam','Barcelona','Rome','Lisbon','Prague','Vienna','Madrid']\n",
    "con = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'\n",
    "update_information(cities,con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next codes are template and test and try codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART1\n",
    "cities = ['Berlin','Paris','Amsterdam','Barcelona','Rome','Lisbon','Prague','Vienna','Madrid']\n",
    "cities_df, cities_error = get_cities(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART2\n",
    "weather_data, cities_df_2 ,weather_error= weather_forcast(cities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART3\n",
    "airports_df, airports_error = get_citys_airports(cities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airports_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART4\n",
    "arrival_flights_df,flights_error = get_arrival_flights(airports_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART5\n",
    "hotels_df,landmark_df,transport_df,error = get_citys_informations(cities_df, my_RapidAPI_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the data in mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all this variables filled in my_keys.py\n",
    "con = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df['elevation'] =cities_df['elevation'].fillna(value=0)#fill na s with 0\n",
    "excist_cities_df = pd.read_sql(\"select * from cities\", con)\n",
    "new_cities_df = cities_df.loc[~cities_df['city'].isin(excist_cities_df['city'])]\n",
    "new_cities_df.to_sql('cities', con=con, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports_df.to_sql('airports', con=con, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.to_sql('weather', con=con, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3568"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrival_flights_df.fillna(value =\"Unknown\").to_sql('arrivals', con=con, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"select * from cities\", con)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a00de2d03a2cdd800050a5fd9903e27ef0ab168083508fb826c5866b9462f56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
